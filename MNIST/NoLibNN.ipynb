{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Creating a Nerual Network without using ML libraries</h2>\n",
    "\n",
    "<p>\n",
    "This notebook will be going over creating a simple nerual network using the classifcal approach of using Stochastic Gradient Descent (SGD) with logistic/sigmoid actication functions and a sqaured mean error cost function.\n",
    "</p>\n",
    "<p>\n",
    "This will be based on the free online book: <a href=\"http://neuralnetworksanddeeplearning.com/chap1.html\">Neural Networks And Deep Learning</a>. This is a decent resource for an theredical and pratical introduction to deep learning with nural networks for beginners in this topic.\n",
    "</p>\n",
    "<p>\n",
    "This is mainly going to be an exercise to brush up on some of the roots of neural networks. Sometimes we get so used to using ML libaries we can get rusty on the core implementations. I'll be incuding theory and code explanations as apart of this notebook.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random and Math libraries along with sigmoid and it's derivative \n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This Sigmoid function below ($\\sigma$) is the activation function that each sigmoid applies to it's input. In otherwords this is the function ran on the input <code>z</code> to give a continuous output between 0 and 1. The derivative of this function is also defined which will be used later for backpropagation ($\\sigma'$)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biases:\n",
      "[array([[-1.09105595],\n",
      "       [-0.39226673],\n",
      "       [-0.03119774]]), array([[1.30886869]])]\n",
      "weights:\n",
      "[array([[-3.82196634,  0.74251693],\n",
      "       [ 1.76050347,  0.34314825],\n",
      "       [ 0.18219338,  1.81397955]]), array([[ 0.45351881, -1.13342251,  0.34959664]])]\n"
     ]
    }
   ],
   "source": [
    "class Network():\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        self.num_layers = len(layers)\n",
    "        self.biases = [np.random.randn(x, 1) for x in layers[1:]]\n",
    "        self.weights = [np.random.randn(x, y)\n",
    "                        for y, x in zip(layers[:-1], layers[1:])]\n",
    "    def sigmoid(self, z):\n",
    "        return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "    def sigmoid_derivative(self, z):\n",
    "        return sigmoid(z)*(1-sigmoid(z))\n",
    "        \n",
    "net = Network([2, 3, 1]) # Example of what biases and weights look like\n",
    "\n",
    "print(\"biases:\")\n",
    "print(net.biases)\n",
    "print(\"weights:\")\n",
    "print(net.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Our network is first defined with an array containing the number of neurons for each layer called <code>layers</code>. Next the <code>biases</code> contain weights between layers. In this case <code>biases[0]</code> is the inital biases for the second layer (the first layer is the input layer and doesn't have biases), and <code>biases[1]</code> is for the output layer.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(Network):\n",
    "    def feed_forward(self, x):\n",
    "        for bias_layer, weight_layer in zip(self.biases, self.weights):\n",
    "            x = sigmoid(np.dot(weight_layer, x) + bias_layer)\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "The method <code>feed_forward</code> takes the input of the network being <code>x</code> and feeds it through the network for an output. This iterates through each layer and applies the activation function being the sigmoid on the input being:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Output = \\sigma(\\vec{weight}\\cdot \\vec{x} + \\vec{bias})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(Network):\n",
    "    # This makes random min batches to apply GD to\n",
    "    def SGD(self, training, learning_rate, epochs, batch_size):\n",
    "        for i in range(epochs):\n",
    "            random.shuffle(training) # Shuffling makes subarrays a random batch\n",
    "            batches = []\n",
    "            # Then we can each batch getting each subarray of length batch_size\n",
    "            for b in range(0, len(training), batch_size):\n",
    "                batches.append(training[b:b+batch_size])\n",
    "            for batch in batches:\n",
    "                self.GD(batch, learning_rate) # Apply GD on each batch\n",
    "            print(\"epoch {0}/{1}\".format(i, epochs)) # Print epoch we are on \n",
    "    \n",
    "    # Applys GD to a mini batch\n",
    "    def GD(batch, learning_rate):\n",
    "        # A 0'd version of weights and biases to keep track of delta changes\n",
    "        change_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        change_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        for x, y in batch:\n",
    "            # Runs backpropagation to get delta's for updating w and b \n",
    "            chg_w_delta, chg_b_delta = self.backpropagate(x, y)\n",
    "            # Go through store all the delta's in the 0'd structures\n",
    "            change_w = [nw+nwd for nw, nwd in zip(change_w, chg_w_delta)]\n",
    "            change_b = [nb+nbd for nb, nbd in zip(change_b, chg_b_delta)]\n",
    "        # Updates the network weights and biases with the changes\n",
    "        effect = learning_rate/len(batch)\n",
    "        self.weights = [w-effect*nw for w, nw in zip(self.weights,change_w)]\n",
    "        self.biases = [b-effect*nb for b, nb in zip(self.biases,change_b)]\n",
    "        \n",
    "    # Applys backpropagation to the network back to front    \n",
    "    def backpropagate(self, x, y):\n",
    "        # A 0'd version of weights and biases to keep track of delta changes\n",
    "        change_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        change_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        # Feedforward and apply activation functions\n",
    "        activations, a = ([x], x)\n",
    "        zs = [] # Stores all z vectors\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            z = np.dot(w, a) + b\n",
    "            zs.append(z)\n",
    "            a = self.sigmoid(z)\n",
    "            activations.append(a)\n",
    "        # Feed backwards to find delta's starting with last layer\n",
    "        cost_derivative = activations[-1] - y\n",
    "        delta = cost_derivative * self.sigmoid_derivative(zs[-1])\n",
    "        change_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "        change_b[-1] = delta\n",
    "        # Now lets do the same with the rest of the layers (l)\n",
    "        for l in range(2, self.num_layers):\n",
    "            z = zs[-1]\n",
    "            layer_weights = self.weights[-l+1].transpose()\n",
    "            layer_activations = activations[-l-1].transpose()\n",
    "            delta = np.dot(layer_weights, delta) * self.sigmoid_derivative(z)\n",
    "            change_w[-1] = np.dot(delta, layer_activations)\n",
    "            change_b[-1] = delta\n",
    "        return (change_w, change_b)\n",
    "    \n",
    "    # Gives the number of results correct given test data by returning the\n",
    "    # Output layer that has the highest activation output\n",
    "    def results(self, test):\n",
    "        results = [(np.argmax(self.feed_forward(x)), y) for (x, y) in test]\n",
    "        return sum(int(x == y) for (x,y) in results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Above the method <code>SGD</code> which splits the training data into groups of random sets of a user defined size. Then <code>GD</code> creates an empty structure to keep track the changes in the delta's and updates the weights and biases for the delta's. The method <code>backpropagate</code> is what takes the mini batch of training data and ther correct response and applies backpropagation through the network to get the delta the weights and biases should be changed by.\n",
    "</p>\n",
    "<p>\n",
    "The last method <code>results</code> simply will go through the input data and feed it through the network. It gets the output nuron which returns the highest value and uses that as the selection. If the selection matches it counts as correct, otherwise it's wrong.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Next lets load in the MNIST dataset for training. I will be using a Keras module to easily load this in purly so we don't need to download a local copy for this example.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-c4a927306f4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\spencer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\spencer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Globally-importable utils.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\spencer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\utils\\conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\spencer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tensorflow'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;31m# Try and load external backend.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\spencer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmoving_averages\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "\n",
    "def loadMNIST():\n",
    "    # input image dimensions\n",
    "    rows, cols = 28, 28\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x_train = x_train.reshape(x_train.shape[0], 1, rows, cols)\n",
    "        x_test = x_test.reshape(x_test.shape[0], 1, rows, cols)\n",
    "        input_shape = (1, rows, cols)\n",
    "    else:\n",
    "        x_train = x_train.reshape(x_train.shape[0], rows, cols, 1)\n",
    "        x_test = x_test.reshape(x_test.shape[0], rows, cols, 1)\n",
    "        input_shape = (rows, cols, 1)\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    print('x_train shape:', x_train.shape)\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    return (x_train, y_train, x_test, y_test, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0b5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
